
    
    
    
    [{"authors":null,"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://gaaaavin.github.io/The-Best-Practices/author/xinhao-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/The-Best-Practices/author/xinhao-liu/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Xinhao Liu","type":"authors"},{"authors":null,"categories":null,"content":"HPC-part-2\nOverview The post introduces the data management system on HPC. The main purpose of this is to provide a foundation for future posts about setting up environments, managing data, and running jobs on HPC.\nThere are four different types of file systems on HPC:\nHome directory: /home/\u0026lt;NetID\u0026gt; Scratch directory: /scratch/\u0026lt;NetID\u0026gt; Archive directory: /archive/\u0026lt;NetID\u0026gt; Vast directory: /vast/\u0026lt;NetID\u0026gt; Each of them has different purposes and limitations. After you login to HPC, you can use the myquota command to check your quota and usage on each file system. A sample output looks like this:\n$ myquota Hostname: log-1 at Sun Mar 21 21:59:08 EDT 2021 Filesystem Environment Backed up? Allocation Current Usage Space Variable /Flushed? Space / Files Space(%) / Files(%) /home $HOME Yes/No 50.0GB/30.0K 8.96GB(17.91%)/33000(110.00%) /scratch $SCRATCH No/Yes 5.0TB/1.0M 811.09GB(15.84%)/2437(0.24%) /archive $ARCHIVE Yes/No 2.0TB/20.0K 0.00GB(0.00%)/1(0.00%) /vast $VAST No/Yes 2.0TB/5.0M 0.00GB(0.00%)/1(0.00%) Note: As you can see, there are two types of limitations for each file system: space and files (also known as inodes). The former is the total amount of space you can use on the file system and the latter is the total number of files you can store on the file system.\nThe existence of file limitation is part of the reason why we need all these best practices in the first place.\nIn the following sections, we will go through each file system in detail.\nüè† Home directory The home directory is the default directory when you log in to HPC. As shown in the output above, the 50GB/30k limitation is quite small. Therefore, you are not recommended to store anything here.\nüìù Scratch directory The scratch directory is the place where you will most play with. It is a temporary storage space for your data and jobs. The 5TB/1M limitation is enough for you to store almost everythin you need.\nNote that this directory is flushed, meaning any inactive files will be deleted after 60 days. When some of your files are about to be flushed, you will receive an email notification.\nHowever, the 1M file limitation is still relatively small, especially for modern datasets that usually contain large number of small files. We will cover details about this in the section for the /vast directory.\nüì¶ Archive directory Like the home directoy, the archive directory is also a permanent storage space. However, it is not accessible from the computing nodes. Therefore, it‚Äôs recommended to use this directory only for archive purpose.\nüìÅ Vast directory The vast directory is an all-flash file system that is optimized for computational workloads with high I/O rates.\nAs mentioned above, as the vast directory has much larger inode limitation, it is recommended to store datasets that contain large number of small files here.\nWe will discuss more about the best practices for large number of small files in future posts.\nRelated posts Previous: HPC Part 1: Access to HPC ","date":1691193600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691193600,"objectID":"1939e4dca010245f7c86b7b6424fc88d","permalink":"https://gaaaavin.github.io/The-Best-Practices/hpc/hpc-data/","publishdate":"2023-08-05T00:00:00Z","relpermalink":"/The-Best-Practices/hpc/hpc-data/","section":"hpc","summary":"HPC-part-2\n","tags":null,"title":"HPC Data Management","type":"hpc"},{"authors":null,"categories":null,"content":"HPC-part-1\nNYU High Performance Computing (NYU HPC) provides access to state of the art supercomputer hardware and cloud services to eligible faculty and students across all of NYU.\nMost of the blog is adapted from this page\nüé¨ Getting started Before accessing the HPC cluster, you need to have an account. If you don‚Äôt have one yet, please obtain one by following step 1 and step 2 in this page.\n‚öôÔ∏è Network configurations Now that you should have an HPC account, we need to configure your network settings to access the HPC cluster.\nIf you are on the NYU network, you can access the HPC cluster directly without any extra configurations.\nOtherwise, you have two options to access the HPC cluster:\nNYU VPN: You can use the NYU VPN to connect to the NYU network. This is often default option for most users. HPC gateway: If in some cases you cannot use the NYU VPN, you can use the HPC gateway gw.hpc.nyu.edu (example below) to connect. Note that it is only a portal-like server, and you cannot run any jobs on it. Ôºû Command line 1. Gateway (Ignore this step if you are using NYU VPN or on the NYU network)\nConnect to the HPC gateway using SSH:\nssh \u0026lt;NetID\u0026gt;@gw.hpc.nyu.edu 2. SSH Connect to the HPC cluster using SSH:\nssh \u0026lt;NetID\u0026gt;@greene.hpc.nyu.edu 3. Save password (Optional) Once you logged in to HPC, you can set up an SSH key to avoid typing your password every time you log in.\n‚ö†Ô∏è Only do this on your trusted computer.\nFirst, generate a SSH key pair on your local machine (disconnecting from HPC):\nssh-keygen -t rsa Then, copy the public key to the HPC cluster:\nssh-copy-id \u0026lt;NetID\u0026gt;@greene.hpc.nyu.edu Now you can log in to HPC without typing your password.\nüìù Editor This section is optional but highly recommended. You can use any editor you like to edit scripts on HPC, here I recommend using VS Code.\n1. Install Download and install VS Code from here.\n2. Install Remote - SSH extension After open VS Code, search for SSH in the extension market and install Remote - SSH. Remote - SSH extension 3. Connect to HPC Click the button in the bottom left corner of VS Code and select Connect to Host.... Then, follow the instructions to connect to HPC.\nConclusion Now you should be able to access the HPC cluster and edit scripts on it.\nRelated posts Next: HPC Part 2: Data management ","date":1690502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690502400,"objectID":"596e8b48216be4b84b64c51f4a8d5a4c","permalink":"https://gaaaavin.github.io/The-Best-Practices/hpc/access_to_hpc/","publishdate":"2023-07-28T00:00:00Z","relpermalink":"/The-Best-Practices/hpc/access_to_hpc/","section":"hpc","summary":"HPC-part-1\n","tags":null,"title":"Accessing HPC","type":"hpc"},{"authors":null,"categories":null,"content":"Again, this is NOT a blog about tutorials.\n‚ùì Why As a researcher who has been involved in various projects and experiments, I have come across numerous instances of incorrect practices being used with common research tools. This incorrect usage has led to flawed results and wasted time.\nI must admit that I too have made some mistakes along the way. However, through my journey, I have learned valuable lessons that have greatly improved my understanding of these tools and their proper usage.\nI am eager to share my experiences, insights, and best practices, as if I hoped that there were someone did the same for me when I was a beginner.\n‚ö†Ô∏è The Importance I don‚Äôt think I need to emphasize the importance of best practices in research.\nMoreover, inappropriate practices can affect other users becuase they often lead to abuse of shared resources. In the end, it makes the workflow inefficient for everyone.\nAs researchers, we strive to make meaningful contributions to our domains. Employing the right practices with research tools plays a pivotal role in achieving that goal.\nüèóÔ∏è Bridging the Gap As a newcomer to the world of research tools, I often found it challenging to locate comprehensive, easy-to-understand resources. Existing documentation can be dense, technical, and difficult to grasp, especially for beginners.\nMy aim in running this blog is to bridge that knowledge gap and provide fellow researchers, particularly newcomers, with practical insights and tips to effectively utilize these tools. I want to make the learning curve less steep for others than it was for me.\nüåü Like or contribute If you find this blog useful, please consider giving it a star on GitHub.\nIf you have any questions or suggestions, please feel free to open an issue or pull request on GitHub.\n","date":1690070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690070400,"objectID":"70a9df5c91f95d16682cd81b636b9fd1","permalink":"https://gaaaavin.github.io/The-Best-Practices/general/motivation/","publishdate":"2023-07-23T00:00:00Z","relpermalink":"/The-Best-Practices/general/motivation/","section":"general","summary":"Again, this is NOT a blog about tutorials.\n","tags":null,"title":"My Motivation for This Blog","type":"general"}]